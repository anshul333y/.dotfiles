#!/bin/bash

# === Config ===
LIMIT=100
PARALLEL_JOBS=5 # Keep low to avoid HTTP 429
SAVE_DIR="$HOME/Pictures/Save"
RESOLUTION="1920x1080"
CATEGORIES="111" # General + Anime + People
PURITY="0"       # SFW only
SORTING="random" # Random wallpapers

# === Setup ===
mkdir -p "$SAVE_DIR"
TMP_COUNTER=$(mktemp)
echo 0 >"$TMP_COUNTER"

# Cleanup lock/temp on exit
cleanup() {
  rm -f "$TMP_COUNTER" "$TMP_COUNTER.lock"
}
trap cleanup EXIT

# === Fetch image URLs ===
echo "📡 Fetching random wallpapers from Wallhaven..."
IMAGE_URLS=()
PAGE=1

while [ "${#IMAGE_URLS[@]}" -lt "$LIMIT" ]; do
  RESPONSE=$(curl -sG "https://wallhaven.cc/api/v1/search" \
    --data-urlencode "categories=$CATEGORIES" \
    --data-urlencode "purity=$PURITY" \
    --data-urlencode "resolutions=$RESOLUTION" \
    --data-urlencode "sorting=$SORTING" \
    --data-urlencode "page=$PAGE")

  NEW_URLS=($(echo "$RESPONSE" | jq -r '.data[].path'))
  IMAGE_URLS+=("${NEW_URLS[@]}")
  ((PAGE++))
done

IMAGE_URLS=("${IMAGE_URLS[@]:0:$LIMIT}")
export SAVE_DIR TMP_COUNTER LIMIT

# === Progress bar updater ===
print_progress() {
  while true; do
    COUNT=$(<"$TMP_COUNTER")
    PERCENT=$((COUNT * 100 / LIMIT))
    DONE=$((PERCENT / 2))
    BAR=$(printf "%-${DONE}s" "#" | tr ' ' '#')
    BAR=$(printf "%-50s" "$BAR" | tr ' ' '.')
    echo -ne "\r[${BAR}] $COUNT/$LIMIT"
    [[ "$COUNT" -ge "$LIMIT" ]] && break
    sleep 0.5
  done
  echo -e "\n✅ Download complete! Saved to: $SAVE_DIR"
}

# === Download one image ===
download_image() {
  URL="$1"
  FILENAME=$(basename "$URL")

  # Small random delay to avoid rate-limiting
  sleep 0.$((RANDOM % 5 + 1))

  # Attempt download with retry
  curl -s --retry 3 --retry-delay 2 --fail "$URL" -o "$SAVE_DIR/$FILENAME" ||
    echo "❌ Failed: $FILENAME"

  # Safely increment shared counter
  (
    flock 200
    COUNT=$(<"$TMP_COUNTER")
    echo $((COUNT + 1)) >"$TMP_COUNTER"
  ) 200>"$TMP_COUNTER.lock"
}

export -f download_image

# === Run downloads with shared progress ===
print_progress &
PROGRESS_PID=$!

printf "%s\n" "${IMAGE_URLS[@]}" | xargs -n 1 -P "$PARALLEL_JOBS" bash -c 'download_image "$0"'

wait $PROGRESS_PID

sxiv -t ~/Pictures/Save/*

mv ~/Pictures/Save/* ~/Pictures/Wallpapers
